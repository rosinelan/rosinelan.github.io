<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>python爬虫 | 持续不断</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="爬虫介绍爬虫定义爬虫是请求网站并提取自己所需要数据的过程。通过我们的程序，可以代替我们向服务器发送请求，然后进行批量的数据下载。   爬虫基本流程 发起请求通过url向服务器发送requests请求，请求可以包含额外的header信息。">
<meta name="keywords" content="爬虫,requests">
<meta property="og:type" content="article">
<meta property="og:title" content="python爬虫">
<meta property="og:url" content="https://rosinelan.github.io/2018/06/13/python爬虫/index.html">
<meta property="og:site_name" content="持续不断">
<meta property="og:description" content="爬虫介绍爬虫定义爬虫是请求网站并提取自己所需要数据的过程。通过我们的程序，可以代替我们向服务器发送请求，然后进行批量的数据下载。   爬虫基本流程 发起请求通过url向服务器发送requests请求，请求可以包含额外的header信息。">
<meta property="og:updated_time" content="2018-06-19T12:37:13.517Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python爬虫">
<meta name="twitter:description" content="爬虫介绍爬虫定义爬虫是请求网站并提取自己所需要数据的过程。通过我们的程序，可以代替我们向服务器发送请求，然后进行批量的数据下载。   爬虫基本流程 发起请求通过url向服务器发送requests请求，请求可以包含额外的header信息。">
  
    <link rel="alternate" href="/atom.xml" title="持续不断" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://rosinelan.github.io"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">首页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">持续不断</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">要松懈的时候再坚持一下</a>
        </h2>
      
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-python爬虫" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/13/python爬虫/" class="article-date">
  <time datetime="2018-06-13T10:02:18.000Z" itemprop="datePublished">2018-06-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/program/">编程</a>►<a class="article-category-link" href="/categories/program/python/">python</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      python爬虫
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h3 id="爬虫介绍"><a href="#爬虫介绍" class="headerlink" title="爬虫介绍"></a>爬虫介绍</h3><h4 id="爬虫定义"><a href="#爬虫定义" class="headerlink" title="爬虫定义"></a>爬虫定义</h4><p>爬虫是请求网站并提取自己所需要数据的过程。通过我们的程序，可以代替我们向服务器发送请求，然后进行批量的数据下载。  </p>
<h4 id="爬虫基本流程"><a href="#爬虫基本流程" class="headerlink" title="爬虫基本流程"></a>爬虫基本流程</h4><ol>
<li>发起请求<br>通过url向服务器发送requests请求，请求可以包含额外的header信息。<a id="more"></a></li>
<li>获取响应内容<br>如果服务器正常响应，那么将受到一个response，response即为我们所请求的网页内容，可能包含html\json\二进制数据(图片、视频)等。</li>
<li>解析内容<br>如果是html代码则可以使用网页解析器进行解析；如果是json数据则可以转换成json对象进行解析；如果是二进制数据则可以保存到文件进行进一步的处理。</li>
<li>保存数据<br>可以保存到本地文件，也可以保存到数据库(mysql\redis\mongodb等)。<h4 id="requests请求"><a href="#requests请求" class="headerlink" title="requests请求"></a>requests请求</h4>当我们通过浏览器向服务器发送requests请求时，这个request包含什么内容？可以通过chrome浏览器的开发人员工具(F12)查看。  </li>
<li>请求方式<br>最常用的请求方式包括get请求和post请求。<br>post请求在开发中最常见的是通过表单进行提交，从用户角度来讲最常见的就是登陆验证。当你需要输入一些信息进行登陆的时候，这次请求就是post请求。<br>get请求最常见的就是搜索回车之后，信息将以?间隔添加在url后面。类似于<code>https://www.baidu.com/s?wd=python3%20requests</code>。而且get请求是用来获取数据，是幂等的。<br>其他还包括put请求(向服务端发送信息从而改变内容)和delete请求(删除资源)。<br>对于资源的操作，其实都可以通过post/get完成，不需要用到put/delete，实际中put/delete也很少用。    </li>
<li>uri统一资源定位符<br>一个网址、一个视频、一个图片都可以用uri去定义</li>
<li>requests headers<br>请求头，包括这次请求的类型，cookie信息以及浏览器类型等。<br>请求头在我们进行网页抓取的时候，服务器会通过解析请求头来进行信息的审核，判断请求是否为合法请求。所以当我们通过程序伪装浏览器进行请求的时候可以设置请求头的信息。  </li>
<li>请求体<br>post请求会把用户信息包装在form-data里面进行提交，因此相比于get请求，post请求的Headers标签的内容会多出Form Data这个信息包。<h4 id="response"><a href="#response" class="headerlink" title="response"></a>response</h4></li>
<li>响应状态<br>通过Headers中的General可以看到<code>status code</code>，使用数字代码表示对于状态，200表示成功，301跳转，404找不到网页，502服务器错误等。</li>
<li>响应头<br>包括内容的类型，cookie信息等。</li>
<li>响应体<br>请求的目的就是为了得到响应体，包括html代码，json及二进制数据等。<h3 id="requests模块"><a href="#requests模块" class="headerlink" title="requests模块"></a>requests模块</h3>安装使用<code>pip install requests</code>即可。  </li>
</ol>
<ul>
<li>通过requests进行网页请求<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line">response = requests.get(<span class="string">'https://www.baidu.com'</span>)  </span><br><span class="line">print(response.text)  <span class="comment">#输出结果为html，中文乱码</span></span><br><span class="line">response.encoding = <span class="string">'utf-8'</span>  <span class="comment">#修改编码</span></span><br><span class="line">print(response.text)  <span class="comment">#输出中文正常</span></span><br><span class="line">print(response.status_code) <span class="comment">#输出状态码，200</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>返回的response为文本时通过<code>response.text</code>读取；图片和视频等二进制文件通过<code>response.content</code>读取。</p>
<ul>
<li>通过添加请求头信息<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.75 Safari/537.36'</span>&#125;</span><br><span class="line"> response1 = requests.get(<span class="string">'https://www.baidu.com'</span>, headers=headers)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>可以通过定义一个列表，然后通过random模块随机取一个header信息进行访问，防止一些反爬虫的操作。  </p>
<ul>
<li><p>获取cookie信息<br>cookie的五要素包括<code>name</code>、<code>value</code>、<code>domain</code>、<code>path</code>和<code>expires</code>。我们可以使用requests模块通过会话信息获取这些信息。<br><code>domain</code><br>代表cookie所在的域，默认情况下就是请求的域名，例如请求<a href="http://www.server1.com/files/hello" target="_blank" rel="noopener">http://www.server1.com/files/hello</a>, 那么响应中的set-Cookie默认会使用www.server1.com作为cookie的domain，在浏览器中也是按照domain来组织cookie的。 我们可以在响应中设置cookie的domain为其他域，但是浏览器并不会去保存这些domain为其他域的cookie。<br><code>path</code> 路径<br>path能够进一步的控制cookie的访问，当path=/，当前域的所有请求都可以访问到这个cookie。如果path设为其他值，比如path=/test,那么只有/test下面的请求可以访问到这个cookie。<br><code>expires</code> 过期时间<br><code>name</code> 对应的key值<br><code>value</code>  key对应的value值  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://www.hao123.com/"</span></span><br><span class="line">session = requests.session()</span><br><span class="line">response = session.get(url=url).text</span><br><span class="line">cookies = session.cookies</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> cookie <span class="keyword">in</span> cookies:</span><br><span class="line">    print(cookie.name)</span><br><span class="line">    print(cookie.value)</span><br><span class="line">    print(cookie.domain)</span><br><span class="line">    print(cookie.path)</span><br><span class="line">    print(cookie.expires)</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用已知的cookie信息访问网站</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">cookie = dict(_ga=<span class="string">"GA1.2.208618761.1528809975"</span>, _gid=<span class="string">"GA1.2.604525626.1528979734"</span>, PHPSESSID=<span class="string">"ait0b8c22ofqpo630cekpc33b6"</span>, _gat=<span class="string">"1"</span>, Hm_lvt_0936ebcc9fa24aa610a0079314fec2d3=<span class="string">"1528809975,1528809984,1528979734,1528980228"</span>, Hm_lpvt_0936ebcc9fa24aa610a0079314fec2d3=<span class="string">"1528980228"</span>, ape__Session=<span class="string">"ait0b8c22ofqpo630cekpc33b6"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://httpbin.org/cookies"</span></span><br><span class="line">session = requests.session()</span><br><span class="line">res = session.get(url=url, cookies=cookie)</span><br><span class="line">res.encoding = res.apparent_encoding</span><br><span class="line">print(res.text)</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用代理访问网站<br>采集信息时为避免IP地址被封，可以使用代理方式访问，可以通过requests模块的proxies属性。  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://2018.ip138.com/ic.asp"</span></span><br><span class="line">proxy = &#123;<span class="string">"http"</span>: <span class="string">"http://221.228.17.172:8181"</span>&#125;</span><br><span class="line">res1 = requests.get(url=url, proxies=proxy)</span><br><span class="line">res2 = requests.get(url=url)</span><br><span class="line">res1.encoding = res1.apparent_encoding</span><br><span class="line">res2.encoding = res2.apparent_encoding</span><br><span class="line">print(res1.text)    <span class="comment">#输出结果为代理IP信息</span></span><br><span class="line">print(<span class="string">"###"</span>*<span class="number">10</span>)</span><br><span class="line">print(res2.text)    <span class="comment">#输出结果为本机IP信息</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>总结</strong><br>requests模块提供的接口，在传输数据的时候，都可以以<code>key:value</code>的形式进行传输，方便数据处理。<br>关于requests中文乱码的问题，可以参考<a href="http://xiaorui.cc/2016/02/19/%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90python-requests%E5%BA%93%E4%B8%AD%E6%96%87%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98/" target="_blank" rel="noopener">Python requests库中文编码问题</a><br>更多关于<code>Requests</code>模块的介绍可以点击<a href="http://docs.python-requests.org/zh_CN/latest/user/quickstart.html" target="_blank" rel="noopener">Requests快速上手</a>查看介绍</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://rosinelan.github.io/2018/06/13/python爬虫/" data-id="cjp86a4v5005vngq693jqplke" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/requests/">requests</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>
  
    
 <script src="/jquery/jquery.min.js"></script>
  <div id="random_posts">
    <h2>推荐文章</h2>
    <div class="random_posts_ul">
      <script>
          var random_count =4
          var site = {BASE_URI:'/'};
          function load_random_posts(obj) {
              var arr=site.posts;
              if (!obj) return;
              // var count = $(obj).attr('data-count') || 6;
              for (var i, tmp, n = arr.length; n; i = Math.floor(Math.random() * n), tmp = arr[--n], arr[n] = arr[i], arr[i] = tmp);
              arr = arr.slice(0, random_count);
              var html = '<ul>';
            
              for(var j=0;j<arr.length;j++){
                var item=arr[j];
                html += '<li><strong>' + 
                item.date + ':&nbsp;&nbsp;<a href="' + (site.BASE_URI+item.uri) + '">' + 
                (item.title || item.uri) + '</a></strong>';
                if(item.excerpt){
                  html +='<div class="post-excerpt">'+item.excerpt+'</div>';
                }
                html +='</li>';
                
              }
              $(obj).html(html + '</ul>');
          }
          $('.random_posts_ul').each(function () {
              var c = this;
              if (!site.posts || !site.posts.length){
                  $.getJSON(site.BASE_URI + 'js/posts.js',function(json){site.posts = json;load_random_posts(c)});
              } 
               else{
                load_random_posts(c);
              }
          });
      </script>
    </div>
  </div>

    
<nav id="article-nav">
  
    <a href="/2018/06/19/python爬虫-二/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          python爬虫(二)
        
      </div>
    </a>
  
  
    <a href="/2018/06/11/python数据处理-二/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">python数据处理(二)</div>
    </a>
  
</nav>

  
</article>
 
     
  <div class="comments" id="comments">
    
     
       
       
      
      
  </div>
 
  

</section>
           
    <aside id="sidebar">
  
    
    <div class="widget-wrap">
    
      <div class="widget" id="toc-widget-fixed">
      
        <strong class="toc-title">文章目录</strong>
        <div class="toc-widget-list">
              <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#爬虫介绍"><span class="toc-number">1.</span> <span class="toc-text">爬虫介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#爬虫定义"><span class="toc-number">1.1.</span> <span class="toc-text">爬虫定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#爬虫基本流程"><span class="toc-number">1.2.</span> <span class="toc-text">爬虫基本流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#requests请求"><span class="toc-number">1.3.</span> <span class="toc-text">requests请求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#response"><span class="toc-number">1.4.</span> <span class="toc-text">response</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#requests模块"><span class="toc-number">2.</span> <span class="toc-text">requests模块</span></a></li></ol>
          </div>
      </div>
    </div>

  
    

  
    
  
    
  
    

  
    
  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-left">
      &copy; 2014 - 2018 小灰灰&nbsp;|&nbsp;
      主题 <a href="https://github.com/giscafer/hexo-theme-cafe/" target="_blank">Cafe</a>
    </div>
     <div id="footer-right">
     联系方式&nbsp;|&nbsp;mqwanghui327@hotmail.com
    </div>
  </div>
</footer>
 <script src="/jquery/jquery.min.js"></script>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    <img class="back-to-top-btn" src="/images/fly-to-top.png"/>
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
      

  

  







<!-- author:forvoid begin -->
<!-- author:forvoid begin -->

<!-- author:forvoid end -->

<!-- author:forvoid end -->



 <script src="/js/is.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
<script src="/js/elevator.js"></script>
  </div>
</body>
</html>